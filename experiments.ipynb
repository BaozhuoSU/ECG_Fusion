{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Model for LightGBM**\n"
      ],
      "metadata": {
        "id": "-GZjzCb3MyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from lightgbm import LGBMClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import clone\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n"
      ],
      "metadata": {
        "id": "gHX4ZQbMQvMy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvOu7kgTIEQ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "features_disease = np.load('Inhouse_health.npy')\n",
        "features_no_disease = np.load('Inhouse_unhealth.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "clf = LGBMClassifier(boosting_type='gbdt', objective='binary', metric='binary_logloss', num_leaves=31, n_estimators=100, learning_rate=0.1, feature_fraction=1,bagging_fraction=0.8, bagging_freq=10)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ka3zFZiWQu6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## **In-house Experiments**"
      ],
      "metadata": {
        "id": "c-zqJAZzNUcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snoRfGe4Qt1X",
        "outputId": "d4ceb1e2-e1b8-42e1-d2a8-9c39061a8d82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.347 (0.327–0.365) 0.715 / 0.615 (0.700–0.734 / 0.597–0.630) 0.992 (0.987–0.997) 0.008 / 0.003 (0.005–0.013 / 0.002–0.003)\n",
            "    Gaussian          Detrended Fractal Dimension    0.331 (0.320–0.351) 0.689 / 0.658 (0.667–0.710 / 0.642–0.674) 0.562 (0.538–0.588) 0.397 / 0.482 (0.381–0.417 / 0.462–0.504)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.357 (0.339–0.375) 0.622 / 0.685 (0.599–0.643 / 0.666–0.709) 0.713 (0.692–0.736) 0.286 / 0.294 (0.269–0.305 / 0.280–0.312)\n",
            "    Gaussian               Katz Fractal Dimension    0.351 (0.333–0.372) 0.710 / 0.597 (0.692–0.732 / 0.579–0.620) 0.676 (0.654–0.700) 0.293 / 0.360 (0.279–0.312 / 0.343–0.383)\n",
            "    Gaussian                       Sample Entropy    0.358 (0.340–0.380) 0.706 / 0.597 (0.686–0.729 / 0.580–0.621) 0.758 (0.736–0.783) 0.245 / 0.141 (0.228–0.264 / 0.139–0.177)\n",
            "    Gaussian                     Spectral Entropy    0.698 (0.678–0.719) 0.333 / 0.285 (0.316–0.354 / 0.270–0.303) 0.799 (0.781–0.821) 0.168 / 0.264 (0.153–0.189 / 0.248–0.287)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.365 (0.350–0.381) 0.615 / 0.663 (0.598–0.636 / 0.648–0.680) 0.363 (0.349–0.380) 0.643 / 0.634 (0.629–0.659 / 0.620–0.651)\n",
            "Non-Gaussian                  Permutation Entropy    0.341 (0.329–0.358) 0.693 / 0.624 (0.669–0.718 / 0.605–0.646) 0.982 (0.971–0.998) 0.076 / 0.010 (0.059–0.095 / 0.001–0.022)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.321 (0.309–0.335) 0.688 / 0.682 (0.671–0.708 / 0.663–0.705) 0.862 (0.840–0.888) 0.227 / 0.071 (0.209–0.247 / 0.054–0.092)\n",
            "       Mixed                             Combined    0.633 (0.611–0.657) 0.618 / 0.115 (0.600–0.639 / 0.098–0.134) 0.984 (0.970–0.999) 0.012 / 0.026 (0.004–0.020 / 0.015–0.040)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PTBXL**"
      ],
      "metadata": {
        "id": "7msdbHHmRvTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features_disease = np.load('PTXBL_unhealth.npy')\n",
        "features_no_disease = np.load('PTBXL_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "clf = LGBMClassifier(boosting_type='gbdt', objective='binary', metric='binary_logloss', num_leaves=31, n_estimators=100, learning_rate=0.1, feature_fraction=1,bagging_fraction=0.8, bagging_freq=10)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "CDLlEH5iQAtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D228VMa3Mxyl",
        "outputId": "1f367718-96e3-4ef9-a82c-74f3289d2666"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.524 (0.509–0.539) 0.463 / 0.494 (0.446–0.490 / 0.472–0.516) 0.654 (0.638–0.673) 0.352 / 0.259 (0.334–0.373 / 0.239–0.279)\n",
            "    Gaussian          Detrended Fractal Dimension    0.604 (0.589–0.624) 0.505 / 0.339 (0.487–0.527 / 0.320–0.359) 0.610 (0.594–0.628) 0.476 / 0.380 (0.457–0.499 / 0.361–0.404)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.528 (0.514–0.545) 0.568 / 0.429 (0.551–0.590 / 0.411–0.448) 0.536 (0.520–0.555) 0.510 / 0.446 (0.491–0.532 / 0.428–0.466)\n",
            "    Gaussian               Katz Fractal Dimension    0.573 (0.557–0.590) 0.372 / 0.435 (0.363–0.395 / 0.418–0.453) 0.570 (0.554–0.586) 0.434 / 0.436 (0.416–0.457 / 0.419–0.456)\n",
            "    Gaussian                       Sample Entropy    0.608 (0.592–0.624) 0.442 / 0.375 (0.424–0.464 / 0.357–0.397) 0.792 (0.775–0.811) 0.179 / 0.230 (0.162–0.199 / 0.213–0.253)\n",
            "    Gaussian                     Spectral Entropy    0.571 (0.556–0.588) 0.463 / 0.404 (0.444–0.482 / 0.385–0.425) 0.661 (0.644–0.681) 0.393 / 0.314 (0.374–0.415 / 0.296–0.336)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.682 (0.668–0.699) 0.400 / 0.280 (0.381–0.423 / 0.262–0.302) 0.915 (0.902–0.932) 0.011 / 0.137 (0.005–0.018 / 0.123–0.157)\n",
            "Non-Gaussian                  Permutation Entropy    0.639 (0.626–0.655) 0.347 / 0.375 (0.329–0.369 / 0.358–0.396) 0.907 (0.893–0.925) 0.063 / 0.013 (0.052–0.077 / 0.006–0.021)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.529 (0.514–0.547) 0.526 / 0.446 (0.507–0.550 / 0.427–0.468) 0.906 (0.891–0.922) 0.074 / 0.107 (0.062–0.087 / 0.092–0.130)\n",
            "       Mixed                             Combined    0.756 (0.743–0.771) 0.368 / 0.179 (0.352–0.386 / 0.162–0.197) 0.958 (0.947–0.971) 0.011 / 0.077 (0.005–0.019 / 0.063–0.096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **InHouse and PTBXL**"
      ],
      "metadata": {
        "id": "5b6TRo0JScS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features_disease = np.load('Inhouse_PTBXL_unhealth.npy')\n",
        "features_no_disease = np.load('Inhouse_PTBXL_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "clf = LGBMClassifier(boosting_type='gbdt', objective='binary', metric='binary_logloss', num_leaves=31, n_estimators=100, learning_rate=0.1, feature_fraction=1,bagging_fraction=0.8, bagging_freq=10)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "Kh_RfZ0wSMcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uykv4MyWS2vf",
        "outputId": "080028d0-447d-4d6a-9995-83fe76f20afd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.694 (0.676–0.714) 0.315 / 0.300 (0.292–0.334 / 0.289–0.317) 0.701 (0.685–0.724) 0.318 / 0.298 (0.296–0.339 / 0.278–0.316)\n",
            "    Gaussian          Detrended Fractal Dimension    0.593 (0.575–0.616) 0.429 / 0.389 (0.410–0.452 / 0.367–0.414) 0.562 (0.545–0.583) 0.456 / 0.436 (0.435–0.479 / 0.421–0.462)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.724 (0.709–0.744) 0.310 / 0.259 (0.294–0.328 / 0.241–0.279) 0.587 (0.571–0.609) 0.490 / 0.406 (0.471–0.516 / 0.383–0.429)\n",
            "    Gaussian               Katz Fractal Dimension    0.669 (0.652–0.688) 0.319 / 0.357 (0.300–0.377 / 0.337–0.377) 0.570 (0.552–0.590) 0.428 / 0.402 (0.410–0.450 / 0.384–0.424)\n",
            "    Gaussian                       Sample Entropy    0.750 (0.732–0.768) 0.226 / 0.316 (0.205–0.245 / 0.296–0.339) 0.803 (0.786–0.824) 0.277 / 0.182 (0.265–0.284 / 0.157–0.197)\n",
            "    Gaussian                     Spectral Entropy    0.633 (0.616–0.651) 0.379 / 0.364 (0.361–0.400 / 0.345–0.384) 0.745 (0.727–0.765) 0.393 / 0.236 (0.374–0.416 / 0.217–0.258)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.794 (0.779–0.813) 0.249 / 0.171 (0.231–0.268 / 0.155–0.193) 0.943 (0.931–0.958) 0.040 / 0.098 (0.016–0.046 / 0.083–0.118)\n",
            "Non-Gaussian                  Permutation Entropy    0.782 (0.765–0.801) 0.242 / 0.200 (0.222–0.261 / 0.183–0.220) 0.987 (0.977–0.992) 0.035 / 0.018 (0.022–0.039 / 0.016–0.029)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.612 (0.597–0.632) 0.465 / 0.317 (0.446–0.483 / 0.298–0.338) 0.796 (0.780–0.816) 0.063 / 0.315 (0.050–0.085 / 0.298–0.336)\n",
            "       Mixed                             Combined    0.861 (0.847–0.877) 0.118 / 0.169 (0.102–0.138 / 0.153–0.190) 0.953 (0.941–0.966) 0.063 / 0.040 (0.048–0.082 / 0.037–0.065)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model for XGBoost"
      ],
      "metadata": {
        "id": "S-rvoV_TT_8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "features_disease = np.load('Inhouse_unhealth.npy')\n",
        "features_no_disease = np.load('Inhouse_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "\n",
        "clf = XGBClassifier(\n",
        "    booster=\"gbtree\",\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "Bu_NYvlFT_o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **In-house**\n"
      ],
      "metadata": {
        "id": "pC6cHmNqUZS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbUSNrSpUJxM",
        "outputId": "05200dca-5783-40c4-b331-94c92d66efcd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.353 (0.330–0.376) 0.703 / 0.598 (0.679–0.732 / 0.583–0.619) 0.993 (0.989–0.996) 0.132 / 0.003 (0.111–0.146 / 0.001–0.006)\n",
            "    Gaussian          Detrended Fractal Dimension    0.360 (0.349–0.379) 0.653 / 0.632 (0.631–0.678 / 0.611–0.654) 0.596 (0.578–0.614) 0.415 / 0.407 (0.396–0.433 / 0.387–0.428)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.393 (0.375–0.410) 0.800 / 0.200 (0.780–0.830 / 0.185–0.225) 0.703 (0.683–0.721) 0.296 / 0.305 (0.277–0.313 / 0.289–0.327)\n",
            "    Gaussian               Katz Fractal Dimension    0.322 (0.308–0.336) 0.741 / 0.628 (0.717–0.769 / 0.605–0.651) 0.666 (0.648–0.685) 0.303 / 0.369 (0.290–0.319 / 0.347–0.390)\n",
            "    Gaussian                       Sample Entropy    0.333 (0.320–0.347) 0.726 / 0.618 (0.703–0.752 / 0.600–0.637) 0.713 (0.695–0.730) 0.307 / 0.273 (0.288–0.326 / 0.254–0.293)\n",
            "    Gaussian                     Spectral Entropy    0.613 (0.595–0.634) 0.457 / 0.314 (0.432–0.483 / 0.291–0.335) 0.743 (0.724–0.762) 0.213 / 0.298 (0.197–0.319 / 0.279–0.319)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.323 (0.312–0.334) 0.658 / 0.693 (0.638–0.679 / 0.677–0.715) 0.313 (0.297–0.328) 0.714 / 0.652 (0.697–0.732 / 0.632–0.673)\n",
            "Non-Gaussian                  Permutation Entropy    0.283 (0.268–0.299) 0.757 / 0.679 (0.736–0.777 / 0.659–0.699) 0.922 (0.908–0.932) 0.106 / 0.055 (0.089–0.120 / 0.042–0.069)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.714 (0.695–0.735) 0.850 / 0.150 (0.830–0.870 / 0.130–0.180) 0.799 (0.781–0.818) 0.332 / 0.095 (0.314–0.350 / 0.080–0.110)\n",
            "       Mixed                             Combined    0.563 (0.544–0.583) 0.725 / 0.151 (0.703–0.747 / 0.133–0.171) 0.932 (0.917–0.948) 0.096 / 0.032 (0.082–0.111 / 0.021–0.046)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PTBXL**"
      ],
      "metadata": {
        "id": "t1T83-AnUZBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "features_disease = np.load('PTXBL_unhealth.npy')\n",
        "features_no_disease = np.load('PTBXL_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "\n",
        "clf = XGBClassifier(\n",
        "    booster=\"gbtree\",\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "WgpOBvpaUZjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re7KBKdYWD4L",
        "outputId": "d6934a38-3417-42b5-a68e-d072adff90a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.510 (0.492–0.528) 0.437 / 0.549 (0.419–0.456 / 0.530–0.571) 0.450 (0.434–0.467) 0.565 / 0.547 (0.546–0.585 / 0.527–0.571)\n",
            "    Gaussian          Detrended Fractal Dimension    0.424 (0.407–0.440) 0.555 / 0.600 (0.536–0.578 / 0.579–0.622) 0.401 (0.384–0.419) 0.701 / 0.487 (0.681–0.723 / 0.469–0.508)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.357 (0.341–0.375) 0.597 / 0.699 (0.577–0.619 / 0.680–0.721) 0.462 (0.444–0.480) 0.574 / 0.499 (0.555–0.595 / 0.480–0.520)\n",
            "    Gaussian               Katz Fractal Dimension    0.537 (0.521–0.556) 0.454 / 0.480 (0.437–0.473 / 0.461–0.500) 0.473 (0.457–0.490) 0.480 / 0.581 (0.461–0.545 / 0.561–0.603)\n",
            "    Gaussian                       Sample Entropy    0.483 (0.466–0.500) 0.575 / 0.457 (0.557–0.597 / 0.438–0.478) 0.778 (0.764–0.797) 0.205 / 0.269 (0.187–0.226 / 0.251–0.290)\n",
            "    Gaussian                     Spectral Entropy    0.503 (0.487–0.518) 0.497 / 0.496 (0.478–0.517 / 0.477–0.517) 0.513 (0.498–0.532) 0.575 / 0.396 (0.557–0.597 / 0.378–0.419)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.642 (0.626–0.659) 0.426 / 0.297 (0.408–0.446 / 0.279–0.319) 0.911 (0.897–0.928) 0.034 / 0.156 (0.022–0.045 / 0.140–0.175)\n",
            "Non-Gaussian                  Permutation Entropy    0.627 (0.614–0.644) 0.368 / 0.396 (0.351–0.385 / 0.378–0.417) 0.956 (0.944–0.969) 0.084 / 0.027 (0.073–0.098 / 0.018–0.038)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.464 (0.446–0.482) 0.571 / 0.498 (0.552–0.591 / 0.479–0.520) 0.879 (0.865–0.896) 0.096 / 0.159 (0.081–0.113 / 0.143–0.179)\n",
            "       Mixed                             Combined    0.680 (0.666–0.696) 0.470 / 0.197 (0.452–0.491 / 0.179–0.217) 0.925 (0.910–0.939) 0.070 / 0.080 (0.063–0.090 / 0.063–0.097)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Aggregated**\n",
        "\n"
      ],
      "metadata": {
        "id": "T3dTJkWSW92T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "features_disease = np.load('Aggregated_unhealth.npy')\n",
        "features_no_disease = np.load('Aggregated_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "\n",
        "clf = XGBClassifier(\n",
        "    booster=\"gbtree\",\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "aDR_pj1NW7Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idHps76VXpPA",
        "outputId": "1fd11bb5-550a-4e83-cc27-f7fd938fcfa7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                 Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.664 (0.635–0.693) 0.45 / 0.26 (0.401–0.499 / 0.225–0.295) 0.647 (0.617–0.677)   0.48 / 0.27 (0.431–0.529 / 0.234–0.306)\n",
            "    Gaussian          Detrended Fractal Dimension    0.526 (0.495–0.557) 0.65 / 0.36 (0.603–0.697 / 0.322–0.398) 0.557 (0.526–0.588)   0.58 / 0.36 (0.532–0.628 / 0.322–0.398)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.669 (0.640–0.698) 0.40 / 0.29 (0.352–0.448 / 0.254–0.326) 0.554 (0.523–0.585)   0.53 / 0.39 (0.481–0.579 / 0.351–0.429)\n",
            "    Gaussian               Katz Fractal Dimension    0.652 (0.622–0.682) 0.45 / 0.28 (0.401–0.499 / 0.244–0.316) 0.531 (0.500–0.562)   0.50 / 0.45 (0.451–0.549 / 0.410–0.490)\n",
            "    Gaussian                       Sample Entropy    0.689 (0.660–0.718) 0.43 / 0.24 (0.381–0.479 / 0.206–0.274) 0.724 (0.696–0.752)   0.38 / 0.21 (0.332–0.428 / 0.177–0.243)\n",
            "    Gaussian                     Spectral Entropy    0.603 (0.573–0.633) 0.55 / 0.30 (0.501–0.599 / 0.263–0.337) 0.635 (0.605–0.665)   0.50 / 0.28 (0.451–0.549 / 0.244–0.316)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.743 (0.716–0.770) 0.38 / 0.18 (0.332–0.428 / 0.149–0.211) 0.933 (0.918–0.948)   0.10 / 0.05 (0.071–0.129 / 0.033–0.067)\n",
            "Non-Gaussian                  Permutation Entropy    0.732 (0.705–0.759) 0.40 / 0.18 (0.352–0.448 / 0.149–0.211) 0.996 (0.992–1.000) 0.005 / 0.003 (0.000–0.012 / 0.000–0.007)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.563 (0.532–0.594) 0.60 / 0.33 (0.552–0.648 / 0.292–0.368) 0.798 (0.773–0.823)   0.28 / 0.15 (0.236–0.324 / 0.121–0.179)\n",
            "       Mixed                             Combined    0.864 (0.843–0.885) 0.20 / 0.09 (0.161–0.239 / 0.067–0.113) 0.937 (0.922–0.952)   0.10 / 0.04 (0.071–0.129 / 0.024–0.056)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model for Random Forest**"
      ],
      "metadata": {
        "id": "HEE_qu5eXuYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "features_disease = np.load('Inhouse_unhealth.npy')\n",
        "features_no_disease = np.load('Inhouse_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=12,\n",
        "    max_features=1.0,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "xWY1FZHfX0Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inhouse**"
      ],
      "metadata": {
        "id": "43dTFvqXYRJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QLuJ-ZIYJtQ",
        "outputId": "c93a7791-e5c7-4ce2-eefe-5a1591845db7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.474 (0.446–0.502) 0.633 / 0.420 (0.586–0.680 / 0.372–0.468) 0.893 (0.876–0.910) 0.130 / 0.085 (0.097–0.163 / 0.058–0.112)\n",
            "    Gaussian          Detrended Fractal Dimension    0.613 (0.585–0.641) 0.465 / 0.310 (0.416–0.514 / 0.265–0.355) 0.559 (0.531–0.587) 0.528 / 0.353 (0.479–0.577 / 0.306–0.400)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.494 (0.466–0.522) 0.608 / 0.405 (0.560–0.656 / 0.357–0.453) 0.545 (0.517–0.573) 0.545 / 0.365 (0.496–0.594 / 0.318–0.412)\n",
            "    Gaussian               Katz Fractal Dimension    0.483 (0.455–0.511) 0.620 / 0.415 (0.573–0.667 / 0.367–0.463) 0.576 (0.548–0.604) 0.508 / 0.340 (0.459–0.557 / 0.293–0.387)\n",
            "    Gaussian                       Sample Entropy    0.536 (0.508–0.564) 0.558 / 0.370 (0.510–0.606 / 0.322–0.418) 0.573 (0.545–0.601) 0.573 / 0.383 (0.524–0.622 / 0.335–0.431)\n",
            "    Gaussian                     Spectral Entropy    0.473 (0.445–0.501) 0.633 / 0.422 (0.586–0.680 / 0.374–0.470) 0.645 (0.617–0.673) 0.425 / 0.285 (0.377–0.473 / 0.240–0.330)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.633 (0.605–0.661) 0.440 / 0.195 (0.391–0.489 / 0.156–0.234) 0.876 (0.858–0.894) 0.148 / 0.067 (0.113–0.181 / 0.042–0.092)\n",
            "Non-Gaussian                  Permutation Entropy    0.317 (0.289–0.345) 0.820 / 0.363 (0.783–0.857 / 0.316–0.410) 0.846 (0.828–0.864) 0.185 / 0.082 (0.147–0.223 / 0.055–0.109)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.517 (0.489–0.545) 0.580 / 0.385 (0.531–0.629 / 0.337–0.433) 0.745 (0.718–0.772) 0.305 / 0.205 (0.260–0.350 / 0.165–0.245)\n",
            "       Mixed                             Combined    0.644 (0.611–0.677) 0.425 / 0.288 (0.377–0.474 / 0.244–0.332) 0.923 (0.906–0.940) 0.092 / 0.042 (0.065–0.119 / 0.022–0.062)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PTBXL**"
      ],
      "metadata": {
        "id": "g3gf8bRcYsOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features_disease = np.load('PTBXL_unhealth.npy')\n",
        "features_no_disease = np.load('PTBXL_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=12,\n",
        "    max_features=1.0,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "sRZVxO1IYu5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYDx0eVBY-pO",
        "outputId": "f4a0cc8b-fc31-4d21-c75a-512e02bdd426"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.644 (0.616–0.672) 0.700 / 0.298 (0.655–0.745 / 0.253–0.343) 0.683 (0.653–0.713) 0.383 / 0.253 (0.339–0.427 / 0.209–0.297)\n",
            "    Gaussian          Detrended Fractal Dimension    0.687 (0.659–0.715) 0.762 / 0.347 (0.721–0.803 / 0.309–0.385) 0.672 (0.643–0.701) 0.625 / 0.347 (0.578–0.672 / 0.309–0.385)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.618 (0.590–0.646) 0.468 / 0.312 (0.430–0.506 / 0.275–0.349) 0.638 (0.610–0.666) 0.445 / 0.295 (0.401–0.489 / 0.260–0.330)\n",
            "    Gaussian               Katz Fractal Dimension    0.653 (0.625–0.681) 0.407 / 0.273 (0.369–0.445 / 0.229–0.317) 0.663 (0.635–0.691) 0.395 / 0.265 (0.351–0.439 / 0.223–0.307)\n",
            "    Gaussian                       Sample Entropy    0.596 (0.568–0.624) 0.492 / 0.328 (0.453–0.531 / 0.288–0.368) 0.716 (0.688–0.744) 0.325 / 0.215 (0.279–0.371 / 0.175–0.255)\n",
            "    Gaussian                     Spectral Entropy    0.623 (0.595–0.651) 0.492 / 0.328 (0.453–0.531 / 0.288–0.368) 0.656 (0.628–0.684) 0.385 / 0.255 (0.339–0.431 / 0.211–0.299)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.597 (0.569–0.625) 0.632 / 0.280 (0.593–0.671 / 0.244–0.316) 0.738 (0.710–0.766) 0.325 / 0.215 (0.279–0.371 / 0.175–0.255)\n",
            "Non-Gaussian                  Permutation Entropy    0.637 (0.609–0.665) 0.445 / 0.295 (0.407–0.483 / 0.257–0.333) 0.789 (0.761–0.817) 0.253 / 0.168 (0.217–0.289 / 0.131–0.205)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.537 (0.509–0.565) 0.565 / 0.375 (0.526–0.604 / 0.337–0.413) 0.745 (0.717–0.773) 0.312 / 0.207 (0.276–0.348 / 0.168–0.246)\n",
            "       Mixed                             Combined    0.773 (0.744–0.802) 0.313 / 0.143 (0.268–0.358 / 0.109–0.178) 0.909 (0.889–0.929) 0.125 / 0.058 (0.093–0.158 / 0.035–0.081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Aggregated**"
      ],
      "metadata": {
        "id": "0STkZoysZaMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features_disease = np.load('Aggregated_unhealth.npy')\n",
        "features_no_disease = np.load('Aggregated_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=12,\n",
        "    max_features=1.0,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "Y-J9cXolZdWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7zZSQ7OuICR",
        "outputId": "027833e0-ef5b-4340-e06d-53070381ee88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                     Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian         Approximate Entropy    0.541 (0.516–0.566) 0.700 / 0.298 (0.655–0.745 / 0.262–0.335) 0.778 (0.748–0.808) 0.333 / 0.148 (0.286–0.379 / 0.120–0.177)\n",
            "    Gaussian Detrended Fractal Dimension    0.492 (0.456–0.528) 0.763 / 0.338 (0.719–0.807 / 0.300–0.376) 0.583 (0.547–0.619) 0.625 / 0.278 (0.578–0.672 / 0.242–0.313)\n",
            "    Gaussian   Higuchi Fractal Dimension    0.693 (0.658–0.728) 0.450 / 0.205 (0.401–0.499 / 0.173–0.237) 0.665 (0.630–0.700) 0.502 / 0.223 (0.460–0.544 / 0.191–0.255)\n",
            "    Gaussian      Katz Fractal Dimension    0.598 (0.564–0.632) 0.603 / 0.268 (0.555–0.650 / 0.233–0.304) 0.697 (0.663–0.731) 0.455 / 0.202 (0.413–0.497 / 0.170–0.234)\n",
            "    Gaussian              Sample Entropy    0.691 (0.656–0.726) 0.525 / 0.165 (0.476–0.574 / 0.135–0.195) 0.792 (0.757–0.827) 0.325 / 0.165 (0.279–0.371 / 0.135–0.195)\n",
            "    Gaussian            Spectral Entropy    0.508 (0.473–0.543) 0.800 / 0.287 (0.761–0.839 / 0.251–0.323) 0.692 (0.657–0.727) 0.385 / 0.287 (0.337–0.433 / 0.251–0.323)\n",
            "Non-Gaussian Petrosian Fractal Dimension    0.579 (0.544–0.614) 0.650 / 0.280 (0.603–0.697 / 0.244–0.316) 0.868 (0.834–0.902) 0.200 / 0.087 (0.161–0.239 / 0.051–0.123)\n",
            "Non-Gaussian         Permutation Entropy    0.654 (0.619–0.689) 0.520 / 0.230 (0.471–0.569 / 0.196–0.264) 0.892 (0.857–0.927) 0.163 / 0.072 (0.126–0.200 / 0.051–0.093)\n",
            "Non-Gaussian       SVD Fractal Dimension    0.598 (0.564–0.632) 0.625 / 0.253 (0.578–0.672 / 0.218–0.288) 0.678 (0.643–0.713) 0.403 / 0.215 (0.356–0.450 / 0.182–0.248)\n",
            "       Mixed                    Combined    0.839 (0.804–0.874) 0.200 / 0.135 (0.161–0.239 / 0.103–0.167) 0.927 (0.892–0.962) 0.110 / 0.048 (0.079–0.141 / 0.031–0.065)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model for SVM**"
      ],
      "metadata": {
        "id": "MSAJuqZOuc7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "features_disease = np.load('Inhouse_unhealth.npy')\n",
        "features_no_disease = np.load('Inhouse_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(\n",
        "        kernel=\"linear\",\n",
        "        C=1.0,\n",
        "        probability=False,\n",
        "        class_weight=None,\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "SnvC52wluclV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inhouse**"
      ],
      "metadata": {
        "id": "H3XiEDiMvNq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpV7eZNQvNbW",
        "outputId": "826a94b8-90af-46a7-9acd-27851f221677"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.496 (0.461–0.531) 0.347 / 0.661 (0.300–0.394 / 0.615–0.707) 0.778 (0.749–0.807) 0.319 / 0.125 (0.273–0.365 / 0.093–0.157)\n",
            "    Gaussian          Detrended Fractal Dimension    0.457 (0.423–0.492) 0.707 / 0.379 (0.662–0.752 / 0.331–0.427) 0.563 (0.529–0.597) 0.603 / 0.271 (0.555–0.651 / 0.227–0.315)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.431 (0.397–0.465) 0.517 / 0.621 (0.468–0.566 / 0.573–0.669) 0.516 (0.481–0.551) 0.623 / 0.345 (0.575–0.671 / 0.298–0.392)\n",
            "    Gaussian               Katz Fractal Dimension    0.464 (0.429–0.499) 0.613 / 0.459 (0.565–0.661 / 0.410–0.508) 0.566 (0.532–0.600) 0.547 / 0.321 (0.498–0.596 / 0.275–0.367)\n",
            "    Gaussian                       Sample Entropy    0.499 (0.464–0.534) 0.298 / 0.704 (0.253–0.343 / 0.659–0.749) 0.568 (0.534–0.602) 0.399 / 0.465 (0.351–0.447 / 0.416–0.514)\n",
            "    Gaussian                     Spectral Entropy    0.462 (0.427–0.497) 0.619 / 0.457 (0.571–0.667 / 0.408–0.506) 0.612 (0.578–0.646) 0.413 / 0.363 (0.365–0.461 / 0.316–0.410)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.441 (0.407–0.475) 0.605 / 0.513 (0.557–0.653 / 0.464–0.562) 0.745 (0.715–0.775) 0.293 / 0.218 (0.248–0.338 / 0.177–0.259)\n",
            "Non-Gaussian                  Permutation Entropy    0.534 (0.499–0.569) 0.543 / 0.389 (0.494–0.592 / 0.341–0.437) 0.771 (0.742–0.800) 0.327 / 0.131 (0.282–0.372 / 0.098–0.164)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.528 (0.493–0.563) 0.613 / 0.331 (0.565–0.661 / 0.285–0.377) 0.712 (0.681–0.743) 0.383 / 0.193 (0.335–0.431 / 0.154–0.232)\n",
            "       Mixed                             Combined    0.619 (0.585–0.653) 0.478 / 0.285 (0.429–0.527 / 0.241–0.329) 0.833 (0.807–0.859) 0.237 / 0.097 (0.195–0.279 / 0.068–0.126)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PTBXL**"
      ],
      "metadata": {
        "id": "knkaYyu-vyhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "features_disease = np.load('PTBXL_unhealth.npy')\n",
        "features_no_disease = np.load('PTBXL_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(\n",
        "        kernel=\"linear\",\n",
        "        C=1.0,\n",
        "        probability=False,\n",
        "        class_weight=None,\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Nv4Ocojxvx_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzaq3RC2wfjW",
        "outputId": "8eecc25d-9d95-40c4-c73d-31a8c49e66d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                              Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian                  Approximate Entropy    0.619 (0.585–0.653) 0.489 / 0.273 (0.440–0.538 / 0.229–0.317) 0.662 (0.629–0.695) 0.389 / 0.287 (0.341–0.437 / 0.243–0.331)\n",
            "    Gaussian          Detrended Fractal Dimension    0.653 (0.620–0.686) 0.372 / 0.322 (0.325–0.419 / 0.276–0.368) 0.637 (0.604–0.670) 0.397 / 0.329 (0.349–0.445 / 0.283–0.375)\n",
            "    Gaussian            Higuchi Fractal Dimension    0.589 (0.555–0.623) 0.513 / 0.309 (0.464–0.562 / 0.264–0.354) 0.585 (0.551–0.619) 0.487 / 0.342 (0.438–0.536 / 0.296–0.389)\n",
            "    Gaussian               Katz Fractal Dimension    0.572 (0.538–0.606) 0.473 / 0.383 (0.424–0.522 / 0.335–0.431) 0.619 (0.585–0.653) 0.482 / 0.299 (0.433–0.531 / 0.254–0.344)\n",
            "    Gaussian                       Sample Entropy    0.556 (0.521–0.591) 0.521 / 0.367 (0.472–0.570 / 0.320–0.414) 0.684 (0.652–0.716) 0.321 / 0.311 (0.275–0.367 / 0.266–0.356)\n",
            "    Gaussian                     Spectral Entropy    0.538 (0.504–0.573) 0.455 / 0.471 (0.406–0.504 / 0.422–0.520) 0.613 (0.579–0.647) 0.372 / 0.402 (0.325–0.419 / 0.354–0.450)\n",
            "Non-Gaussian          Petrosian Fractal Dimension    0.511 (0.476–0.546) 0.409 / 0.569 (0.361–0.457 / 0.520–0.618) 0.709 (0.678–0.741) 0.387 / 0.195 (0.339–0.435 / 0.156–0.234)\n",
            "Non-Gaussian                  Permutation Entropy    0.579 (0.545–0.613) 0.487 / 0.355 (0.438–0.536 / 0.308–0.402) 0.742 (0.712–0.772) 0.327 / 0.189 (0.281–0.373 / 0.151–0.227)\n",
            "Non-Gaussian Singular Value Decomposition Entropy    0.502 (0.467–0.537) 0.593 / 0.403 (0.545–0.641 / 0.355–0.451) 0.698 (0.666–0.730) 0.333 / 0.271 (0.287–0.379 / 0.227–0.314)\n",
            "       Mixed                             Combined    0.697 (0.665–0.729) 0.371 / 0.235 (0.324–0.418 / 0.193–0.277) 0.857 (0.834–0.881) 0.217 / 0.069 (0.177–0.257 / 0.044–0.094)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Aggregated**"
      ],
      "metadata": {
        "id": "O9L5au-Dwlva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "features_disease = np.load('Aggregated_unhealth.npy')\n",
        "features_no_disease = np.load('Aggregated_health.npy')\n",
        "\n",
        "random_indices_disease = np.random.choice(features_disease.shape[0], 1000, replace=False)\n",
        "random_indices_no_disease = np.random.choice(features_no_disease.shape[0], 1000, replace=False)\n",
        "\n",
        "features_disease_random = features_disease[random_indices_disease]\n",
        "features_no_disease_random = features_no_disease[random_indices_no_disease]\n",
        "\n",
        "features_no_disease_random = features_no_disease_random[0:features_disease_random.shape[0]]\n",
        "\n",
        "labels_disease = np.ones(features_disease_random.shape[0])\n",
        "labels_no_disease = np.zeros(features_no_disease_random.shape[0])\n",
        "\n",
        "features = np.concatenate([features_disease_random, features_no_disease_random], axis=0)\n",
        "labels = np.concatenate([labels_disease, labels_no_disease], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(features_disease, bins=100, alpha=0.5, label='disease')\n",
        "plt.hist(features_no_disease, bins=100, alpha=0.5, label='no disease')\n",
        "plt.show()\n",
        "\n",
        "data = pd.DataFrame(features)\n",
        "data['label'] = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1].values, data.iloc[:, -1].values, random_state=42, stratify=data.iloc[:, -1].values, test_size=0.2)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(\n",
        "        kernel=\"linear\",\n",
        "        C=1.0,\n",
        "        probability=False,\n",
        "        class_weight=None,\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "_YWmImUhws6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "def _metrics_from_cm(cm):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = (tp + tn) / cm.sum()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else np.nan\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else np.nan\n",
        "    return acc, fpr, fnr\n",
        "\n",
        "def _bootstrap_ci(model, X, y, n_boot=500, seed=2025):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    y_hat_all = model.predict(X)\n",
        "    accs, fprs, fnrs = [], [], []\n",
        "    for _ in range(n_boot):\n",
        "        idx = rng.choice(len(y), len(y), replace=True)\n",
        "        cm = confusion_matrix(y[idx], y_hat_all[idx], labels=[0,1])\n",
        "        acc, fpr, fnr = _metrics_from_cm(cm)\n",
        "        accs.append(acc); fprs.append(fpr); fnrs.append(fnr)\n",
        "    def ci(arr):\n",
        "        arr = np.asarray(arr)\n",
        "        lo, hi = np.nanpercentile(arr, [2.5, 97.5])\n",
        "        return float(np.nanmean(arr)), float(lo), float(hi)\n",
        "    return ci(accs), ci(fprs), ci(fnrs)\n",
        "\n",
        "def _fmt_triplet(t):\n",
        "    mean, lo, hi = t\n",
        "    return f\"{mean:.3f} ({lo:.3f}–{hi:.3f})\"\n",
        "\n",
        "def evaluate_pair(name_dist, name_feat, X_tr, y_tr, X_te, y_te,\n",
        "                  model_norm, model_fusion):\n",
        "    model_norm.fit(X_tr, y_tr)\n",
        "    cm_norm = confusion_matrix(y_te, model_norm.predict(X_te), labels=[0,1])\n",
        "    acc_n, fpr_n, fnr_n = _metrics_from_cm(cm_norm)\n",
        "    (acc_n_m, acc_n_lo, acc_n_hi), (fpr_n_m, fpr_n_lo, fpr_n_hi), (fnr_n_m, fnr_n_lo, fnr_n_hi) = _bootstrap_ci(model_norm, X_te, y_te)\n",
        "\n",
        "    model_fusion.fit(X_tr, y_tr)\n",
        "    cm_fu = confusion_matrix(y_te, model_fusion.predict(X_te), labels=[0,1])\n",
        "    acc_f, fpr_f, fnr_f = _metrics_from_cm(cm_fu)\n",
        "    (acc_f_m, acc_f_lo, acc_f_hi), (fpr_f_m, fpr_f_lo, fpr_f_hi), (fnr_f_m, fnr_f_lo, fnr_f_hi) = _bootstrap_ci(model_fusion, X_te, y_te)\n",
        "\n",
        "    row = {\n",
        "        \"Distribution\": name_dist,\n",
        "        \"Feature\": name_feat,\n",
        "        \"Normalization Accuracy\": f\"{acc_n_m:.3f} ({acc_n_lo:.3f}–{acc_n_hi:.3f})\",\n",
        "        \"Normalization FPR / FNR\": f\"{fpr_n_m:.3f} / {fnr_n_m:.3f} ({fpr_n_lo:.3f}–{fpr_n_hi:.3f} / {fnr_n_lo:.3f}–{fnr_n_hi:.3f})\",\n",
        "        \"Fusion Accuracy\": f\"{acc_f_m:.3f} ({acc_f_lo:.3f}–{acc_f_hi:.3f})\",\n",
        "        \"Fusion FPR / FNR\": f\"{fpr_f_m:.3f} / {fnr_f_m:.3f} ({fpr_f_lo:.3f}–{fpr_f_hi:.3f} / {fnr_f_lo:.3f}–{fnr_f_hi:.3f})\",\n",
        "    }\n",
        "    return row\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Gaussian\": {\n",
        "        \"Approximate Entropy\": slice(0, 1),\n",
        "        \"Detrended Fractal Dimension\": slice(1, 2),\n",
        "        \"Higuchi Fractal Dimension\": slice(2, 3),\n",
        "        \"Katz Fractal Dimension\": slice(3, 4),\n",
        "        \"Sample Entropy\": slice(4, 5),\n",
        "        \"Spectral Entropy\": slice(5, 6),\n",
        "    },\n",
        "    \"Non-Gaussian\": {\n",
        "        \"Petrosian Fractal Dimension\": slice(6, 7),\n",
        "        \"Permutation Entropy\": slice(7, 8),\n",
        "        \"Singular Value Decomposition Entropy\": slice(8, 9),\n",
        "    },\n",
        "    \"Mixed\": {\n",
        "        \"Combined\": slice(None),\n",
        "    },\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for dist_name, groups in feature_groups.items():\n",
        "    for feat_name, cols in groups.items():\n",
        "        Xtr = X_train[:, cols]\n",
        "        Xte = X_test[:, cols]\n",
        "        norm_model = make_pipeline(StandardScaler(), clone(clf))\n",
        "        fusion_model = clone(clf)\n",
        "        rows.append(\n",
        "            evaluate_pair(dist_name, feat_name, Xtr, y_train, Xte, y_test,\n",
        "                          norm_model, fusion_model)\n",
        "        )\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Distribution\",\"Feature\",\n",
        "    \"Normalization Accuracy\",\"Normalization FPR / FNR\",\n",
        "    \"Fusion Accuracy\",\"Fusion FPR / FNR\"\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI5tTgCmw2vD",
        "outputId": "9b45193a-c2d3-43ea-f26f-6fb37bdc0e0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution                     Feature Normalization Accuracy                   Normalization FPR / FNR     Fusion Accuracy                          Fusion FPR / FNR\n",
            "    Gaussian         Approximate Entropy    0.562 (0.528–0.596) 0.365 / 0.487 (0.318–0.412 / 0.447–0.527) 0.763 (0.737–0.789) 0.283 / 0.207 (0.239–0.327 / 0.175–0.239)\n",
            "    Gaussian Detrended Fractal Dimension    0.518 (0.487–0.549) 0.542 / 0.442 (0.493–0.590 / 0.402–0.482) 0.571 (0.540–0.602) 0.336 / 0.491 (0.290–0.382 / 0.451–0.531)\n",
            "    Gaussian   Higuchi Fractal Dimension    0.667 (0.638–0.696) 0.525 / 0.205 (0.476–0.574 / 0.173–0.237) 0.674 (0.645–0.703) 0.489 / 0.217 (0.440–0.538 / 0.184–0.250)\n",
            "    Gaussian      Katz Fractal Dimension    0.564 (0.533–0.595) 0.481 / 0.406 (0.432–0.530 / 0.367–0.445) 0.619 (0.589–0.649) 0.421 / 0.354 (0.373–0.469 / 0.316–0.392)\n",
            "    Gaussian              Sample Entropy    0.679 (0.650–0.708) 0.452 / 0.234 (0.403–0.501 / 0.200–0.268) 0.747 (0.720–0.774) 0.355 / 0.205 (0.279–0.371 / 0.173–0.237)\n",
            "    Gaussian            Spectral Entropy    0.536 (0.501–0.571) 0.512 / 0.432 (0.463–0.561 / 0.392–0.472) 0.684 (0.655–0.713) 0.298 / 0.328 (0.253–0.343 / 0.290–0.366)\n",
            "Non-Gaussian Petrosian Fractal Dimension    0.502 (0.466–0.538) 0.503 / 0.495 (0.454–0.552 / 0.455–0.535) 0.843 (0.820–0.866) 0.319 / 0.049 (0.273–0.365 / 0.032–0.066)\n",
            "Non-Gaussian         Permutation Entropy    0.574 (0.544–0.604) 0.351 / 0.476 (0.304–0.398 / 0.436–0.516) 0.873 (0.852–0.894) 0.165 / 0.102 (0.129–0.201 / 0.078–0.126)\n",
            "Non-Gaussian       SVD Fractal Dimension    0.542 (0.508–0.577) 0.318 / 0.598 (0.272–0.364 / 0.550–0.646) 0.627 (0.597–0.657) 0.292 / 0.427 (0.247–0.337 / 0.387–0.467)\n",
            "       Mixed                    Combined    0.782 (0.756–0.808) 0.263 / 0.188 (0.220–0.306 / 0.157–0.219) 0.892 (0.873–0.911) 0.117 / 0.102 (0.085–0.149 / 0.078–0.126)\n"
          ]
        }
      ]
    }
  ]
}